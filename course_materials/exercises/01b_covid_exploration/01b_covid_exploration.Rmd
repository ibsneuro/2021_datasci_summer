---
title: Basic introduction to data exploration / visualisation using data from the
  coronavirus package
author: "Ina Bornkessel-Schlesewsky"
output: html_document
---

```{r load_packages, message=FALSE, warning=FALSE}
library(tidyverse)
library(Hmisc)
library(coronavirus)
library(emo)

# ignore the following code for now -- it will be explained later!
coronavirus <- coronavirus %>% 
  as_tibble()
```

## R Markdown

This is an R Markdown document. It mixes text and analysis code and can be used to easily produce reports such as the one on cumulative Covid-related deaths that we saw earlier. It is also useful for your own data analysis workflow, as it allows you to keep notes on your analysis and the analysis code in the same document. As we will see later, this is extremely useful for a reproducible workflow.

From the RStudio RMarkdown template:

> Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

> When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.

We will look at how Markdown works in more detail later on in the course. For now, just be aware that anything you type outside of the R chunks will be rendered as text and anything inside the chunks will be run as code.

You can embed an R code chunk like this:

```{r coronavirus_data}
# Within a chunk, anything preceded by a hash is a comment
# Anything else is actual code and will be run when you knit the document
# The following line of code shows us the first six rows of the coronavirus data frame 
head(coronavirus)
```

The chunk of code above illustrates an important basic principle of how R works: a command or function -- also known as a "verb" -- (`head` in this example) is applied to an object (the data frame `coronavirus`). This manipulates the object in some way: in the case of `head`, outputting the first few lines of a data frame.

To get more information on a function, type `?function` into the RStudio console. Try this for `?head`.

## Start exploring the *coronavirus* data

### Understanding the structure of the data

When you start working with a new data set, you need to understand the structure and content of the data, i.e. what is the shape of the data frame (how many columns and rows) and what does the content of the different columns look like?

R provides the in-built function `summary` for this, which is particularly useful for numeric columns. To get a bit more detail, we also use the function `describe` from the `Hmisc` package.
Note the similar syntax to what we did with `head` above: we're simply applying different functions to the same object (i.e. doing different "stuff" with it `r emo::ji("wink")`).

Note also the notation of referring to columns as *variables* and rows as *observations* -- once again, more on this later.

```{r summarise_data}
summary(coronavirus)

describe(coronavirus)

```

We know now that `coronavirus` contains data from January 2020 to January 2021 for 191 different countries and that it provides information (via the variable `type`) on the number of confirmed cases, deaths and recovered cases. 

### Extracting subsets of data: confirmed cases in South Australia

Let's say we're interested in the number of confirmed cases in South Australia over time. To do this, we need to know how to extract subsets of the data. This is done using the verb `filter`, which serves to select certain rows according to a specified criterion.

First, let's try extracting all observations for South Australia. Here, the pipe operator (%>%) directs the `gapminder` data set to the `filter` command. Note that we're not changing the original dataframe, we're just selecting observations and printing the result. `filter` and the other data transformation commands that we use below are loaded as part of the `tidyverse` package (technically speaking, they're part of the `dplyr` package, which is one of the packages making up the overall `tidyverse`). We will generally load the full `tidyverse` for convenience.

```{r basic_filtering}
coronavirus %>% 
  filter(province == "South Australia")
```

Note: the "==" here is a logical equals, which is what we use when we look at an equivalence of values.

We can do the same to isolate just the confirmed cases by filtering on *type*.

```{r basic_filtering2}
coronavirus %>% 
  filter(type == "confirmed")
```

But we of course want to combine both of these criteria to look at all confirmed cases in South Australia. This is easy to do:

```{r combined_filtering}
coronavirus %>% 
  filter(province == "South Australia" & type == "confirmed")
```

We want to do some more exploration on this particular subset of the data. So let's save it as a new object using the assignment operator `<-`. Note how the syntax is exactly the same as above except for the fact that we're saving the output as a new object `SA_confirmed` using `<-`.

```{r create_new_object}

SA_confirmed <- coronavirus %>% 
  filter(province == "South Australia" & type == "confirmed")

```

With our new data frame `SA_confirmed`, we can now start asking some more useful questions. For example, we can look at only those days where SA recorded confirmed cases -- again using `filter`.

```{r SA_above_0_confirmed}

SA_confirmed %>% 
  filter(cases > 0)

```

This shows that we actually recorded our first case at the beginning of February 2020. This was quite surprising to me!

Also note the difference between filtering for numeric variables such as *cases* and character variables such as *province*. A value for *province* (such as *South Australia* needs to be enclosed in quotes as it is a character string. A value for *cases* (such as 0), by contrast, is numeric and doesn't need to be enclosed in quotes.

### Sorting data: days with the highest numbers of confirmed cases

What if we want to look at the worst days in terms of the number of confirmed cases? The easiest way to do this is to sort by the number of cases using the `arrange` verb. Note how the syntax is exactly the same as for `filter`: the only thing that changes is the operation conducted.

```{r basic_arrange}

SA_confirmed %>% 
  arrange(cases)
```

Sorting by the number of confirmed cases shows that there were negative case numbers on some days ... What's going on here? `r emo::ji("thinking")` If we were doing a real analysis of these data, we would probably want to figure this out before proceeding!

*Exercise: See if you can figure out what the negative numbers mean. Hint: you can get more information on the data and their source by typing `?coronavirus` into the console.*

What we would really like to do is sort in a descending order (i.e. with the highest number of cases at the top). This is easily done by adding a minus sign (*-*).

```{r basic_arrange2}

SA_confirmed %>% 
  arrange(-cases)
```

### Combining operations

Note that we can also sequence verbs such as `filter` and `arrange`. If we wanted to extract observations where there had been > 0 deaths in Victoria, for example, and then sort in descending order, this is easily accomplished:

```{r victoria_deaths}
coronavirus %>% 
  filter(province == "Victoria" & type == "death" & cases > 0) %>% 
  arrange(-cases)

```

*Exercise: insert a new chunk of R code and modify it to show the same data as above but for South Australia. How does the worst day for deaths in SA compare to that in VIC?*

## Basic data visualisation

Visualisation is one of the most powerful tools for exploring and understanding what's in your data. It is also incredibly important when it comes to communicating the results of your analysis: as the saying goes, "a picture is worth a thousand words"! Luckily, R -- and specifically the `ggplot2` package (also part of the tidyverse) -- makes it easy to produce beautiful, publication-quality plots, even for those of us who are not natural graphic designers at heart (like me! `r emo::ji("sunglasses")`). Let's take it for a spin!

We'll start with a simple example: how did the number of confirmed Covid cases in South Australia develop over time?

```{r plot_confirmed_cases_SA}

ggplot(data = SA_confirmed, aes(x = date, y = cases)) +
  geom_col()

```

Basic ggplot syntax: you need to specify the data (i.e. *SA_confirmed* in this case) and the aesthetics (`aes`): these are the visual dimensions of a graph that are used to communicate information. You need to specify how the data map onto these dimensions, e.g. here: *date* maps onto the x-axis and *cases* onto the y-axis. We then add a geometric object layer using `geom_*`; here, we use `geom_col`, which produces a bar chart that represents values in the data. There's lots of other options as we shall see. Note that we use the plus sign (*+*) here to add the geom layer rather than the pipe (*%>%*), as we're **adding** a layer rather than channelling an object to a new command. 

Overall then, our plot is composed of the data, the aes mapping and a layer specifying the geometric object.

By changing the type of geom, we can change the type of graph. It is super easy to change to a line graph, for example, by using `geom_line`:

```{r plot_confirmed_cases_SA_line}

ggplot(data = SA_confirmed, aes(x = date, y = cases)) +
  geom_line()

```

Note how the syntax is exactly the same as before -- we merely change our choice of geom!

`ggplot` also makes it easy to compare different groups, for example the timeline of confirmed cases across different states. We start by using colour to distinguish groups.

```{r plot_confirmed_cases_by_state}
# create a new data frame that only includes confirmed cases in Australia
AUS_confirmed <- coronavirus %>% 
  filter(country == "Australia" & type == "confirmed")

# note how we can easily distinguish groups by colour, simply by adding the colour aesthetic
ggplot(data = AUS_confirmed, aes(x = date, y = cases, colour = province)) + 
  geom_line()

```

Another way to distinguish groups is to use facets, i.e. a separate graph per group. This is done in a slightly different way:

```{r plot_confirmed_cases_by_state_facet}
ggplot(data = AUS_confirmed, aes(x = date, y = cases)) + 
  geom_line() +
  facet_wrap(~ province)

```

We can also combine both colour and faceting!

```{r plot_confirmed_cases_by_state_facet2}
ggplot(data = AUS_confirmed, aes(x = date, y = cases, colour = province)) + 
  geom_line() +
  facet_wrap(~ province)

```

Notice how the inclusion of the legend messes up our x-axis labels a bit. We will see how to fix this later, when we discuss the customisation of plots.

For now, we will finish by looking at how to enhance your plot by adding a title, changing axis labels etc. and how to save to a publication-quality image file.

```{r plot_with_title_etc}

ggplot(data = AUS_confirmed, aes(x = date, y = cases, colour = province)) + 
  geom_line() +
  ggtitle("Confirmed Covid-19 cases in Australia by state") +
  xlab("Date") +
  ylab("Daily cases")

# you can easily save the last plot created by using ggsave
# and voilà, you have a publication-quality figure!
ggsave("confirmed_cases_by_state.jpg", width = 180, units = "mm", dpi = 300)

```


### Other verbs: `select` and `mutate` 

*Note: if you're feeling a bit overwhelmed at this point, you can just skip this section for now and come back to it later.*

So far, we have seen that just two verbs -- `filter`, `arrange` (and their combination) -- already provide us with lots of powerful options for data exploration. However, these are just two of six core verbs in the `dplyr` package (part of the `tidyverse`). As outlined [here](https://dplyr.tidyverse.org), these are a "consistent set of verbs that help you solve the most common data manipulation challenges":

* `filter()` -- select cases based on values
* `arrange()` -- reorder rows
* `select()` -- select variables based on names
* `mutate()` -- add new variables as a function of existing ones
* `summarise()` -- reduce multiple values to a summary statistic

Here, we briefly examine `select` and `mutate`.

As its name suggests, `select` lets you select variables based on their names. This is useful, for example, when you are reading in a big data set with many variables that you don't need. In our case, we might not be interested in latitude and longitude values, for example, and thus want to remove these columns. To do this, we apply `select` to the variables that we want to keep:

```{r select_example1}
coronavirus %>% 
  select(date, province, country, type, cases)

```

Alternatively, we can specify the variables that we want to "deselect" by using a minus sign:

```{r select_example2}
coronavirus %>% 
  select(-lat, -long)

```

Let's say we now wanted to normalise the number of confirmed cases by population for better comparability. To do this, we use `mutate` to create a new variable *cases_norm*, drawing on a population estimate of 1,769,319 for SA (estimated population in June 2020 according to [Wikipedia](https://en.wikipedia.org/wiki/South_Australia):

```{r confirmed_cases_normalised_sa}
coronavirus %>% 
  # only keep observations with cases > 0 to reduce the amount of data
  filter(province == "South Australia" & type == "confirmed" & cases > 0) %>% 
  mutate(cases_norm = cases / 1769319)
```

From this, we can calculate incidence rates, e.g. per 100,000 people. Note how we can create multiple new variables with only one use of `mutate` and how the second variable created can draw on the first.  

```{r confirmed_cases_incidence_sa}
coronavirus %>% 
  # only keep observations with cases > 0 to reduce the amount of data
  filter(province == "South Australia" & type == "confirmed" & cases > 0) %>% 
  mutate(cases_norm = cases / 1769319,
         incidence = cases_norm * 100000) %>% 
  arrange(-incidence)
```

#### Exercises

*Exercise 1: calculate the incidence rate of confirmed Covid cases per 100,000 population for another state of your choice. How does it compare to the one for SA?*

*Exercise 2: calculate the incidence rate (as above) for all Australian observations and then plot the incidence rate across time by state* 



